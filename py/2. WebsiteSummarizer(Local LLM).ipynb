{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eef52fe-86af-4267-b42b-88841e0e2fa1",
   "metadata": {},
   "source": [
    "# Web-Summary Notebook — LM Studio\n",
    "_A tiny utility to fetch a page → extract text → ask the model for a short summary._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92de8eb",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f2ebec0-3783-4142-a5ea-db1f63ba6a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868237c0",
   "metadata": {},
   "source": [
    "### OpenAI-compatible client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ab13a24-844b-4328-96c2-e529a9dbc9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure OpenAI-compatible client (GLM endpoint)\n",
    "client = OpenAI(\n",
    "  base_url=\"http://localhost:1234/v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d2edfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! It's great to meet you! I'm excited to be your first conversation partner. How can I assist you today? Do you have any questions, topics you'd like to discuss, or just want to chat? I'm all ears (or rather, all text)!\n"
     ]
    }
   ],
   "source": [
    "# quick smoke test (optional)\n",
    "message = \"Hello, Llama 3.2! This is my first ever message to you! Hi!\"\n",
    "response = client.chat.completions.create(model=\"llama-3.2-3b-instruct\", messages=[{\"role\":\"user\", \"content\":message}])\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0281438",
   "metadata": {},
   "source": [
    "### Web fetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0831545a-1d36-42e9-afc8-c2984ad8365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some websites need proper headers when fetching them\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    def __init__(self, url):\n",
    "        \"\"\"Create this Website object from the given url using BeautifulSoup.\"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers, timeout=20)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        # strip junk\n",
    "        for irrelevant in soup.body([\"script\",\"style\",\"img\",\"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True) if soup.body else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e5f002c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rohith's Portfolio\n",
      "RP.\n",
      "Home\n",
      "Skills\n",
      "Experience\n",
      "Education\n",
      "Projects\n",
      "Contact\n",
      "Home\n",
      "Skills\n",
      "Experience\n",
      "Education\n",
      "Projects\n",
      "Contact\n",
      "Rohith Goud Panjala\n",
      "Full-Stack Software Engineer & Problem Solver\n",
      "Engineering Scalable & Impactful Solutions\n",
      "I'm a Full-Stack Software Engineer who builds fast, scalable, and intelligent systems that solve real-world problems. I thrive on turning complexity into clarity by designing solutions that are clean, efficient, and built to last. With a sharp eye for detail and a passion for technology, I bring energy and ownership to every project I touch. I don't just code. I deliver outcomes, move fast, and grow with every challenge.\n",
      "Resume\n",
      "Get In Touch\n",
      "Scroll\n",
      "My Skills\n",
      "Technical expertise and tools I work with\n",
      "Scroll\n",
      "Work Experience\n",
      "My professional journey and key contributions\n",
      "Jun 2024 - Aug 2024\n",
      "Software Engineer Intern\n",
      "ZROin\n",
      "Remote (Baltimore, MD)\n",
      "Engineered scalable backend services in Nest.js, enhancing ZROin's platform for 50+ small businesses by integrating 3D store designs and e-commerce features.\n",
      "Key Achievements\n",
      "→\n",
      "Engineered scalable backend services in Nest.js, enhancing ZROin's platform for 50+ small businesses by integrating 3D store designs and e-commerce features.\n",
      "→\n",
      "Collaborated with Baltimore City government and a cross-functional team to deploy solutions on GCP, ensuring reliability and scalability.\n",
      "→\n",
      "Developed RESTful APIs that seamlessly integrated with modern frontend frameworks, ensuring optimal data flow and system performance.\n",
      "Nest.js\n",
      "Angular.js\n",
      "Socket.io\n",
      "Matterport 3D\n",
      "GCP\n",
      "Node.js\n",
      "TypeScript\n",
      "MongoDB\n",
      "RESTful APIs\n",
      "Jun 2024 - Aug 2024\n",
      "Backend Developer Intern\n",
      "Reel Talk\n",
      "Remote (Los Angeles, CA)\n",
      "Developed a real-time backend for web, iOS, and Android platforms using Firebase, GCP, Node.js, and Express.js.\n",
      "Key Achievements\n",
      "→\n",
      "Developed a real-time backend for web, iOS, and Android platforms using Firebase, GCP, Node.js, and Express.js.\n",
      "→\n",
      "Optimized system performance by managing large-scale data integration and implementing security measures.\n",
      "→\n",
      "Implemented comprehensive data synchronization between platforms, ensuring consistent user experience across all devices.\n",
      "Firebase\n",
      "Firestore\n",
      "GCP\n",
      "Node.js\n",
      "Express.js\n",
      "Figma\n",
      "Sep 2023 - Apr 2024\n",
      "Research Assistant\n",
      "The Ethical Software Lab, UMBC\n",
      "Baltimore, MD\n",
      "Designed and implemented full-stack web/mobile applications, contributing to ethical software research.\n",
      "Key Achievements\n",
      "→\n",
      "Designed and implemented full-stack web/mobile applications, contributing to ethical software research.\n",
      "→\n",
      "Developed robust solutions while collaborating on research-based development initiatives.\n",
      "→\n",
      "Applied software engineering principles to create ethical technology solutions addressing real-world challenges.\n",
      "React.js\n",
      "Node.js\n",
      "PostgreSQL\n",
      "React Native\n",
      "MongoDB\n",
      "Figma\n",
      "Spring Boot\n",
      "Hibernate\n",
      "Java\n",
      "AWS\n",
      "Jira\n",
      "Git\n",
      "Adobe XD\n",
      "Dec 2021 - Mar 2023\n",
      "Programmer Analyst\n",
      "Cognizant Technology Solutions\n",
      "Remote (Hyderabad, India)\n",
      "Built a full-stack app using React.js and Node.js, integrating Medable's backend to support scalable clinical workflows.\n",
      "Key Achievements\n",
      "→\n",
      "Built a full-stack app using React.js and Node.js, integrating Medable's backend to support scalable clinical workflows.\n",
      "→\n",
      "Designed RESTful APIs for frontend-backend communication and secure patient data handling.\n",
      "→\n",
      "Improved page load and data fetch performance by 30% via frontend and API optimizations.\n",
      "→\n",
      "Collaborated with QA, product, and design teams to deliver features aligned with real-world healthcare workflows.\n",
      "React.js\n",
      "Node.js\n",
      "HTML5\n",
      "CSS3\n",
      "styled-components\n",
      "Bootstrap\n",
      "TanStack Query\n",
      "RESTful APIs\n",
      "MongoDB\n",
      "Git\n",
      "Figma\n",
      "Jenkins\n",
      "Scroll\n",
      "Education\n",
      "My academic background and qualifications\n",
      "2023\n",
      "-\n",
      "2025\n",
      "Aug 2023 - May 2025\n",
      "Master of Professional Studies in Software Engineering\n",
      "University of Maryland Baltimore County\n",
      "Baltimore, MD\n",
      "GPA:\n",
      "3.87/4.0\n",
      "2017\n",
      "-\n",
      "2021\n",
      "Aug 2017 - Aug 2021\n",
      "Bachelor of Technology in Electronics and Communication Engineering\n",
      "Guru Nanak Institutions (GNI)\n",
      "Hyderabad, India\n",
      "Scroll\n",
      "My Projects\n",
      "Showcasing my technical expertise and problem-solving abilities\n",
      "CRWLR - Terms of Service & Privacy Policy Analyzer\n",
      "A full-stack cloud-native platform for crawling, summarizing, and analyzing legal documents using AI and NLP.\n",
      "About the Project\n",
      "CRWLR is an innovative solution designed to address the complexity and opacity of legal documents like Terms of Service and Privacy Policies. The platform utilizes advanced AI and NLP techniques to crawl websites, extract legal documents, and provide concise, understandable summaries for users. This capstone project for UMBC delivers intelligent insights that help individuals and businesses make more informed decisions about the services they use.\n",
      "Technical Implementation\n",
      "Frontend\n",
      "Developed a responsive UI using Next.js 15 with Tailwind CSS, integrated Clerk for authentication, and deployed on Vercel.\n",
      "Backend\n",
      "Built robust backend services in FastAPI, featuring Gemini API integration for AI-driven summarization, deployed on Google Cloud Run. Leveraged Typesense for efficient data indexing.\n",
      "Custom Crawler Engine\n",
      "Engineered a custom crawler using BeautifulSoup and Playwright, seamlessly integrated with the RESTful backend.\n",
      "DevOps & Infrastructure\n",
      "Implemented a full CI/CD pipeline with GitHub Actions and designed a secure document processing infrastructure.\n",
      "Challenges & Learnings\n",
      "Challenges:\n",
      "One of the major challenges was designing a robust crawler that could identify and extract the correct legal documents from various website layouts and structures. Another challenge was optimizing the AI processing to provide accurate summaries while managing costs.\n",
      "Learnings:\n",
      "This project deepened my understanding of integrating AI APIs effectively, designing performant crawlers, and building secure document processing pipelines. It also taught me valuable lessons about data indexing and search optimization.\n",
      "Technologies Used\n",
      "Next.js 15\n",
      "FastAPI\n",
      "Tailwind CSS\n",
      "Gemini API\n",
      "Clerk\n",
      "Typesense\n",
      "Playwright\n",
      "BeautifulSoup\n",
      "GitHub Actions\n",
      "Google Cloud Run\n",
      "Vercel\n",
      "GitHub\n",
      "Scroll\n",
      "Get In Touch\n",
      "Let's connect and discuss opportunities\n",
      "Looking to hire a developer?\n",
      "Let's discuss opportunities!\n",
      "Contact About Opportunities\n",
      "rohithgp30@gmail.com\n",
      "Or connect with me on\n",
      "LinkedIn\n",
      "GitHub\n",
      "I'm currently\n",
      "open to new opportunities\n",
      "and would love to hear from you!\n",
      "My GitHub Activity\n",
      "A snapshot of my coding journey\n",
      "Back to top\n",
      "©\n",
      "2025\n",
      "Rohith Goud Panjala\n",
      ". All rights reserved.\n",
      "Built with Next.js and Tailwind CSS\n"
     ]
    }
   ],
   "source": [
    "rp = Website(\"https://rp30.us\")\n",
    "print(rp.title)\n",
    "print(rp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a104825",
   "metadata": {},
   "source": [
    "### Prompt builders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d2bfff6-676e-4c4d-87e6-3fa95e90778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system prompt — tweak freely\n",
    "system_prompt = (\n",
    "    \"You are an assistant that analyzes the contents of a website \"\n",
    "    \"and provides a short summary, ignoring navigation text. \"\n",
    "    \"Respond in markdown.\"\n",
    ")\n",
    "\n",
    "def user_prompt_for(website: Website):\n",
    "    up = f\"You are looking at a website titled {website.title}\\n\"\n",
    "    up += \"The contents of this website is as follows:\\n\"\n",
    "    up += \"Please provide a short summary of this website in markdown.\\n\"\n",
    "    up += \"If it includes news or announcements, summarize these too.\\n\\n\"\n",
    "    up += website.text\n",
    "    return up\n",
    "\n",
    "def messages_for(website: Website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0532b086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are looking at a website titled Rohith's Portfolio\n",
      "The contents of this website is as follows:\n",
      "Please provide a short summary of this website in markdown.\n",
      "If it includes news or announcements, summarize these too.\n",
      "\n",
      "RP.\n",
      "Home\n",
      "Skills\n",
      "Experience\n",
      "Education\n",
      "Projects\n",
      "Contact\n",
      "Home\n",
      "Skills\n",
      "Experience\n",
      "Education\n",
      "Projects\n",
      "Contact\n",
      "Rohith Goud Panjala\n",
      "Full-Stack Software Engineer & Problem Solver\n",
      "Engineering Scalable & Impactful Solutions\n",
      "I'm a Full-Stack Software Engineer who builds fast, scalable, and intelligent systems that solve real-world problems. I thrive on turning complexity into clarity by designing solutions that are clean, efficient, and built to last. With a sharp eye for detail and a passion for technology, I bring energy and ownership to every project I touch. I don't just code. I deliver outcomes, move fast, and grow with every challenge.\n",
      "Resume\n",
      "Get In Touch\n",
      "Scroll\n",
      "My Skills\n",
      "Technical expertise and tools I work with\n",
      "Scroll\n",
      "Work Experience\n",
      "My professional journey and key contributions\n",
      "Jun 2024 - Aug 2024\n",
      "Software Engineer Intern\n",
      "ZROin\n",
      "Remote (Baltimore, MD)\n",
      "Engineered scalable backend services in Nest.js, enhancing ZROin's platform for 50+ small businesses by integrating 3D store designs and e-commerce features.\n",
      "Key Achievements\n",
      "→\n",
      "Engineered scalable backend services in Nest.js, enhancing ZROin's platform for 50+ small businesses by integrating 3D store designs and e-commerce features.\n",
      "→\n",
      "Collaborated with Baltimore City government and a cross-functional team to deploy solutions on GCP, ensuring reliability and scalability.\n",
      "→\n",
      "Developed RESTful APIs that seamlessly integrated with modern frontend frameworks, ensuring optimal data flow and system performance.\n",
      "Nest.js\n",
      "Angular.js\n",
      "Socket.io\n",
      "Matterport 3D\n",
      "GCP\n",
      "Node.js\n",
      "TypeScript\n",
      "MongoDB\n",
      "RESTful APIs\n",
      "Jun 2024 - Aug 2024\n",
      "Backend Developer Intern\n",
      "Reel Talk\n",
      "Remote (Los Angeles, CA)\n",
      "Developed a real-time backend for web, iOS, and Android platforms using Firebase, GCP, Node.js, and Express.js.\n",
      "Key Achievements\n",
      "→\n",
      "Developed a real-time backend for web, iOS, and Android platforms using Firebase, GCP, Node.js, and Express.js.\n",
      "→\n",
      "Optimized system performance by managing large-scale data integration and implementing security measures.\n",
      "→\n",
      "Implemented comprehensive data synchronization between platforms, ensuring consistent user experience across all devices.\n",
      "Firebase\n",
      "Firestore\n",
      "GCP\n",
      "Node.js\n",
      "Express.js\n",
      "Figma\n",
      "Sep 2023 - Apr 2024\n",
      "Research Assistant\n",
      "The Ethical Software Lab, UMBC\n",
      "Baltimore, MD\n",
      "Designed and implemented full-stack web/mobile applications, contributing to ethical software research.\n",
      "Key Achievements\n",
      "→\n",
      "Designed and implemented full-stack web/mobile applications, contributing to ethical software research.\n",
      "→\n",
      "Developed robust solutions while collaborating on research-based development initiatives.\n",
      "→\n",
      "Applied software engineering principles to create ethical technology solutions addressing real-world challenges.\n",
      "React.js\n",
      "Node.js\n",
      "PostgreSQL\n",
      "React Native\n",
      "MongoDB\n",
      "Figma\n",
      "Spring Boot\n",
      "Hibernate\n",
      "Java\n",
      "AWS\n",
      "Jira\n",
      "Git\n",
      "Adobe XD\n",
      "Dec 2021 - Mar 2023\n",
      "Programmer Analyst\n",
      "Cognizant Technology Solutions\n",
      "Remote (Hyderabad, India)\n",
      "Built a full-stack app using React.js and Node.js, integrating Medable's backend to support scalable clinical workflows.\n",
      "Key Achievements\n",
      "→\n",
      "Built a full-stack app using React.js and Node.js, integrating Medable's backend to support scalable clinical workflows.\n",
      "→\n",
      "Designed RESTful APIs for frontend-backend communication and secure patient data handling.\n",
      "→\n",
      "Improved page load and data fetch performance by 30% via frontend and API optimizations.\n",
      "→\n",
      "Collaborated with QA, product, and design teams to deliver features aligned with real-world healthcare workflows.\n",
      "React.js\n",
      "Node.js\n",
      "HTML5\n",
      "CSS3\n",
      "styled-components\n",
      "Bootstrap\n",
      "TanStack Query\n",
      "RESTful APIs\n",
      "MongoDB\n",
      "Git\n",
      "Figma\n",
      "Jenkins\n",
      "Scroll\n",
      "Education\n",
      "My academic background and qualifications\n",
      "2023\n",
      "-\n",
      "2025\n",
      "Aug 2023 - May 2025\n",
      "Master of Professional Studies in Software Engineering\n",
      "University of Maryland Baltimore County\n",
      "Baltimore, MD\n",
      "GPA:\n",
      "3.87/4.0\n",
      "2017\n",
      "-\n",
      "2021\n",
      "Aug 2017 - Aug 2021\n",
      "Bachelor of Technology in Electronics and Communication Engineering\n",
      "Guru Nanak Institutions (GNI)\n",
      "Hyderabad, India\n",
      "Scroll\n",
      "My Projects\n",
      "Showcasing my technical expertise and problem-solving abilities\n",
      "CRWLR - Terms of Service & Privacy Policy Analyzer\n",
      "A full-stack cloud-native platform for crawling, summarizing, and analyzing legal documents using AI and NLP.\n",
      "About the Project\n",
      "CRWLR is an innovative solution designed to address the complexity and opacity of legal documents like Terms of Service and Privacy Policies. The platform utilizes advanced AI and NLP techniques to crawl websites, extract legal documents, and provide concise, understandable summaries for users. This capstone project for UMBC delivers intelligent insights that help individuals and businesses make more informed decisions about the services they use.\n",
      "Technical Implementation\n",
      "Frontend\n",
      "Developed a responsive UI using Next.js 15 with Tailwind CSS, integrated Clerk for authentication, and deployed on Vercel.\n",
      "Backend\n",
      "Built robust backend services in FastAPI, featuring Gemini API integration for AI-driven summarization, deployed on Google Cloud Run. Leveraged Typesense for efficient data indexing.\n",
      "Custom Crawler Engine\n",
      "Engineered a custom crawler using BeautifulSoup and Playwright, seamlessly integrated with the RESTful backend.\n",
      "DevOps & Infrastructure\n",
      "Implemented a full CI/CD pipeline with GitHub Actions and designed a secure document processing infrastructure.\n",
      "Challenges & Learnings\n",
      "Challenges:\n",
      "One of the major challenges was designing a robust crawler that could identify and extract the correct legal documents from various website layouts and structures. Another challenge was optimizing the AI processing to provide accurate summaries while managing costs.\n",
      "Learnings:\n",
      "This project deepened my understanding of integrating AI APIs effectively, designing performant crawlers, and building secure document processing pipelines. It also taught me valuable lessons about data indexing and search optimization.\n",
      "Technologies Used\n",
      "Next.js 15\n",
      "FastAPI\n",
      "Tailwind CSS\n",
      "Gemini API\n",
      "Clerk\n",
      "Typesense\n",
      "Playwright\n",
      "BeautifulSoup\n",
      "GitHub Actions\n",
      "Google Cloud Run\n",
      "Vercel\n",
      "GitHub\n",
      "Scroll\n",
      "Get In Touch\n",
      "Let's connect and discuss opportunities\n",
      "Looking to hire a developer?\n",
      "Let's discuss opportunities!\n",
      "Contact About Opportunities\n",
      "rohithgp30@gmail.com\n",
      "Or connect with me on\n",
      "LinkedIn\n",
      "GitHub\n",
      "I'm currently\n",
      "open to new opportunities\n",
      "and would love to hear from you!\n",
      "My GitHub Activity\n",
      "A snapshot of my coding journey\n",
      "Back to top\n",
      "©\n",
      "2025\n",
      "Rohith Goud Panjala\n",
      ". All rights reserved.\n",
      "Built with Next.js and Tailwind CSS\n"
     ]
    }
   ],
   "source": [
    "print(user_prompt_for(rp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dba719",
   "metadata": {},
   "source": [
    "## My Runs\n",
    "List any sites you want summarized below and run the next cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73c268b",
   "metadata": {},
   "source": [
    "### Model call + display helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a12f92bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = client.chat.completions.create(\n",
    "        model = \"llama-3.2-3b-instruct\",\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2aebfaf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Rohith's Portfolio Summary\\n==========================\\n\\n**Overview**\\n---------------\\n\\nRohith's portfolio showcases his experience as a Full-Stack Software Engineer & Problem Solver. He has worked on various projects, including scalable backend services, real-time backend development, and ethical software research.\\n\\n### Education\\n\\n* Master of Professional Studies in Software Engineering (2023-2025), University of Maryland Baltimore County\\n* Bachelor of Technology in Electronics and Communication Engineering (2017-2021), Guru Nanak Institutions (GNI)\\n\\n### Work Experience\\n\\n#### Jun 2024 - Aug 2024: Software Engineer Intern, ZROin\\nEngineered scalable backend services using Nest.js, enhancing the platform for small businesses.\\n\\n#### Jun 2024 - Aug 2024: Backend Developer Intern, Reel Talk\\nDeveloped a real-time backend for web, iOS, and Android platforms using Firebase, GCP, Node.js, and Express.js.\\n\\n#### Sep 2023 - Apr 2024: Research Assistant, The Ethical Software Lab, UMBC\\nDesigned and implemented full-stack web/mobile applications contributing to ethical software research.\\n\\n### Projects\\n\\n* CRWLR (Terms of Service & Privacy Policy Analyzer): A cloud-native platform utilizing AI and NLP techniques to analyze legal documents.\\n\\t+ Built using Next.js 15, FastAPI, Tailwind CSS, Gemini API, Clerk, Typesense, Playwright, and BeautifulSoup.\\n\\n### Skills\\n\\n* Full-Stack Software Engineering\\n* Node.js\\n* TypeScript\\n* MongoDB\\n* RESTful APIs\\n* Nest.js\\n* Angular.js\\n* Socket.io\\n* Matterport 3D\\n* GCP\\n* Firebase\\n* Express.js\\n* React.js\\n* PostgreSQL\\n* React Native\\n* Spring Boot\\n* Hibernate\\n* Java\\n* AWS\\n* Jira\\n* Git\\n* Adobe XD\\n\\n### Get in Touch\\n\\nRohith is currently open to new opportunities and would love to hear from you. You can contact him through email or connect with him on LinkedIn, GitHub, or other platforms.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"https://rp30.us\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f161521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Rohith's Portfolio**\n",
       "=====================================\n",
       "\n",
       "### Overview\n",
       "\n",
       "Rohith's portfolio showcases his expertise as a Full-Stack Software Engineer, highlighting his technical skills and accomplishments in various projects.\n",
       "\n",
       "### Recent News/Announcements\n",
       "\n",
       "None mentioned on the website.\n",
       "\n",
       "### Summary of Content\n",
       "\n",
       "The website is divided into sections:\n",
       "\n",
       "*   **Introduction**: A brief introduction to Rohith, highlighting his role as a Full-Stack Software Engineer.\n",
       "*   **Skills**: Technical expertise and tools used by Rohith.\n",
       "*   **Experience**: Work experience section with achievements in software engineering internships at ZROin, Reel Talk, and The Ethical Software Lab, UMBC.\n",
       "*   **Education**: Academic background, including his Master of Professional Studies in Software Engineering from the University of Maryland Baltimore County.\n",
       "*   **Projects**: Showcase of technical expertise and problem-solving abilities through capstone projects like CRWLR - Terms of Service & Privacy Policy Analyzer.\n",
       "\n",
       "### Projects\n",
       "\n",
       "CRWLR is a full-stack cloud-native platform for crawling, summarizing, and analyzing legal documents using AI and NLP. This project demonstrates Rohith's ability to:\n",
       "\n",
       "*   Design robust solutions\n",
       "*   Integrate AI APIs effectively\n",
       "*   Build secure document processing pipelines\n",
       "*   Optimize performance\n",
       "\n",
       "Rohith's portfolio highlights his expertise as a Full-Stack Software Engineer, with a strong focus on problem-solving and technical skills.\n",
       "\n",
       "### Technical Details\n",
       "\n",
       "*   Technologies used: Next.js 15, FastAPI, Tailwind CSS, Gemini API, Clerk, Typesense, Playwright, BeautifulSoup, GitHub Actions, Google Cloud Run, Vercel.\n",
       "*   Frontend framework: Next.js 15 with Tailwind CSS\n",
       "*   Backend services: Robust backend services built using FastAPI featuring Gemini API integration for AI-driven summarization\n",
       "\n",
       "### Contact Information\n",
       "\n",
       "Rohith can be reached through his email (rohithgp30@gmail.com) or connected on LinkedIn and GitHub."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A function to display this nicely in the Jupyter output, using markdown\n",
    "display_summary(\"https://rp30.us\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23ffd72",
   "metadata": {},
   "source": [
    "### Let's try more websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9173e7be",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': 'Trying to keep the first 4575 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdisplay_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://cnn.com\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mdisplay_summary\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdisplay_summary\u001b[39m(url):\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     summary = \u001b[43msummarize\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     display(Markdown(summary))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36msummarize\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msummarize\u001b[39m(url):\n\u001b[32m      2\u001b[39m     website = Website(url)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mllama-3.2-3b-instruct\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages_for\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwebsite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.choices[\u001b[32m0\u001b[39m].message.content\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/llms/lib/python3.11/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/llms/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py:1147\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1144\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1145\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1146\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/llms/lib/python3.11/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/llms/lib/python3.11/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': 'Trying to keep the first 4575 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}"
     ]
    }
   ],
   "source": [
    "display_summary(\"https://cnn.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e38fad21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Anthropic Website Summary\n",
       "=====================================\n",
       "\n",
       "**About**\n",
       "-----------\n",
       "\n",
       "Anthropic is a public benefit corporation dedicated to securing the benefits and mitigating the risks of AI. They aim to build tools that serve humanity's long-term well-being.\n",
       "\n",
       "**Research Focus**\n",
       "-----------------\n",
       "\n",
       "Anthropic focuses on building responsible AI technologies, such as Claude, which is an agent for coding and computer use. Their research emphasizes safety at the frontier, exploring topics like agentic misalignment, alignment, and interpretability.\n",
       "\n",
       "**News and Announcements**\n",
       "-------------------------\n",
       "\n",
       "*   **Claude Sonnet 4.5**: The best model in the world for agents, coding, and computer use.\n",
       "*   **Claude Opus 4.1**: A new product release.\n",
       "*   **Project Vend**: An announcement on a new project (August 2025)\n",
       "*   **Tracing the thoughts of a large language model**: An announcement on interpretability research (March 2025)\n",
       "\n",
       "**Products**\n",
       "------------\n",
       "\n",
       "Anthropic offers various products, including:\n",
       "\n",
       "*   Claude: A powerful agent for coding and computer use.\n",
       "*   Claude Code: A developer platform for building with Claude.\n",
       "*   Max plan, Team plan, Enterprise plan: Pricing plans for different users.\n",
       "\n",
       "**Company Information**\n",
       "----------------------\n",
       "\n",
       "Anthropic is a company dedicated to responsible AI development. They have an **Anthropic Academy** where users can learn to build with Claude, and they offer various programs like the **Startups program**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://anthropic.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8919322c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# OpenAI Website Summary\n",
       "=====================================\n",
       "\n",
       "The OpenAI website provides an overview of the company's research, products, and services. The main sections include:\n",
       "\n",
       "*   **Research**: Details on various AI-related projects and advancements, such as GPT-5, Sora 2, and OpenAI o3.\n",
       "*   **Safety**: Information on security measures and transparency in OpenAI's models.\n",
       "*   **For Business**: Solutions for businesses, including enterprise, education, and API platforms.\n",
       "*   **About Us**: Company history, charter, careers, and brand guidelines.\n",
       "\n",
       "## Recent News Announcements\n",
       "\n",
       "### Upcoming Events\n",
       "\n",
       "*   **OpenAI DevDay 2025**: Catch up on recent announcements.\n",
       "*   **Sora 2 is here**: A new version of Sora was released on September 30, 2025.\n",
       "\n",
       "### Product Updates\n",
       "\n",
       "*   **Codex is now generally available**: Codex is a conversational AI model that can be integrated into various applications.\n",
       "*   **AgentKit, new Evals, and RFT for agents**: AgentKit provides tools for creating more effective agents in chatbots.\n",
       "*   **Buy it in ChatGPT: Instant Checkout and the Agentic Commerce Protocol**: A new feature allowing users to purchase items directly within ChatGPT.\n",
       "\n",
       "### Partnerships and Collaborations\n",
       "\n",
       "*   **AMD and OpenAI announce strategic partnership to deploy 6 gigawatts of AMD GPUs**: A partnership aimed at accelerating AI research and development.\n",
       "\n",
       "## Publications\n",
       "\n",
       "The website also features articles on various AI-related topics, including:\n",
       "\n",
       "*   Measuring the performance of OpenAI's models on real-world tasks.\n",
       "*   Detecting and reducing scheming in AI models.\n",
       "\n",
       "These publications provide insights into OpenAI's approaches to developing safe and effective AI models."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://openai.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f24242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
